 🌐 SafeWeb – AI-Powered Emotional Safety for Women Online
Empowering women to reclaim their digital space.
SafeWeb is a powerful Chrome extension designed to detect and blur toxic content in real-time, offer supportive responses, and notify users—or guardians in the case of minors—about emotionally harmful online interactions. We’re starting with Instagram, and expanding to other platforms across the web.

💡 Why SafeWeb?
Online spaces are becoming increasingly hostile, especially for women and children. With over 70% of women reporting online harassment, and social platforms often falling short in offering proactive solutions, SafeWeb fills the gap by acting as a real-time digital ally—providing emotional safety, privacy control, and responsible reporting.

🚀 Features
🔍 AI-Based Toxicity Detection
Identifies harmful, offensive, or abusive language in real-time.

🛡️ Custom Safe Zones
Users can define which sections or accounts they want filtered for peace of mind.

🤖 Smart Reply Assistant
Suggests emotionally intelligent, non-confrontational replies to toxic messages.

📸 Auto Screenshot & Reporting
Automatically captures and stores harmful interactions for user review or reporting.

👨‍👩‍👧 Parental Notification System
For minors, alerts are sent to guardians for any severe or recurring toxicity incidents.

🛠 Tech Stack & Architecture
SafeWeb combines traditional web technologies, cutting-edge AI/ML models, and decentralized technologies to deliver emotional safety at scale. Here's a breakdown of our complete stack and solution pipeline:

⚙️ Tech Stack
🌐 Frontend
Chrome Extension using JavaScript, HTML, CSS

Web3 Frontend: Ethers.js

Mobile Support (Future): Flutter, React Native

🧠 AI/ML & NLP
Toxicity Detection: Detoxify, Google Perspective API

OCR & Text Extraction: Custom OCR pipeline

ML Model Serving: TensorFlow, Firebase ML

🧱 Backend
Server & APIs: Node.js, Express.js

Database: MongoDB

Authentication & Notifications: Firebase Auth, Cloud Functions, Firebase Cloud Messaging

🕸️ Web3 Integration
Blockchain: Ethereum / Polygon

Smart Contracts: Solidity

Decentralized Moderation: DAO-based flag review system

🧩 Solution Architecture
1. User Interaction & Input Stage
Users interact via extension or web interface

Upload screenshots or link accounts

Choose how to handle toxic content (Blur, Remove, Notify)

2. Text Extraction & Toxicity Detection
OCR tools extract text from screenshots

Detoxify model + keyword detection + AI context check to assess explicit and implicit toxicity

3. Content Processing & Decision Making
Based on user settings:

Blur overlays toxic content

Remove deletes it

Notify sends real-time alerts to user or guardian

Real-time detection for incoming messages

4. Blocking & Preventive Measures
Auto-blocks repeat offenders

Adds them to a “Detected Harassers” list

Users can manually manage blocked accounts

Future upgrades include predictive sentiment analysis

5. Reporting & Community Involvement
Users can flag content to a Decentralized Moderation DAO

Community votes + AI confidence scores decide outcomes

Ensures fairness and transparency

6. Future Enhancements
Multilingual toxicity detection

Mobile app rollout

Sentiment analysis for deeper insight

Expanded platform compatibility beyond Instagram




